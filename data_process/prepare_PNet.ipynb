{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare PNet-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box, boxes):\n",
    "    \"\"\"Compute IoU between detect box and gt boxes\n",
    "    Parameters:\n",
    "    ----------\n",
    "    box: numpy array , shape (5, ): x1, y1, x2, y2, score\n",
    "        input box\n",
    "    boxes: numpy array, shape (n, 4): x1, y1, x2, y2\n",
    "        input ground truth boxes\n",
    "    Returns:\n",
    "    -------\n",
    "    ovr: numpy.array, shape (n, )\n",
    "        IoU\n",
    "    \"\"\"\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    # box = (x1, y1, w, h)\n",
    "    #box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "    box_area = box[2] * box[3]\n",
    "    #area = (boxes[:, 2] - boxes[:, 0] + 1) * (boxes[:, 3] - boxes[:, 1] + 1)\n",
    "    area = boxes[:,2]*boxes[:,3]\n",
    "    # abtain the offset of the interception of union between crop_box and gt_box\n",
    "    xx1 = np.maximum(box[0], boxes[:, 0])\n",
    "    yy1 = np.maximum(box[1], boxes[:, 1])\n",
    "    #xx2 = np.minimum(box[2], boxes[:, 2])\n",
    "    #yy2 = np.minimum(box[3], boxes[:, 3])\n",
    "    \n",
    "    xx2 = np.minimum(box[0]+box[2]-1, boxes[:, 2]+boxes[:,0]-1)\n",
    "    yy2 = np.maximum(box[1]+box[3]-1, boxes[:, 1]+boxes[:,3]-1)\n",
    "    \n",
    "    # compute the width and height of the bounding box\n",
    "    w = np.maximum(0, xx2 - xx1)\n",
    "    h = np.maximum(0, yy2 - yy1)\n",
    "\n",
    "    inter = w * h\n",
    "    ovr = inter / (box_area + area - inter)\n",
    "    return ovr\n",
    "\n",
    "\n",
    "def convert_to_square(bbox):\n",
    "    \"\"\"Convert bbox to square\n",
    "    Parameters:\n",
    "    ----------\n",
    "    bbox: numpy array , shape n x 5\n",
    "        input bbox\n",
    "    Returns:\n",
    "    -------\n",
    "    square bbox\n",
    "    \"\"\"\n",
    "    square_bbox = bbox.copy()\n",
    "\n",
    "    #h = bbox[:, 3] - bbox[:, 1] + 1\n",
    "    #w = bbox[:, 2] - bbox[:, 0] + 1\n",
    "    \n",
    "    h = bbox[:,3]\n",
    "    \n",
    "    w = bbox[:,2]\n",
    "    \n",
    "    max_side = np.maximum(h,w)\n",
    "    square_bbox[:, 0] = bbox[:, 0] + w*0.5 - max_side*0.5\n",
    "    square_bbox[:, 1] = bbox[:, 1] + h*0.5 - max_side*0.5\n",
    "    square_bbox[:, 2] = square_bbox[:, 0] + max_side - 1\n",
    "    square_bbox[:, 3] = square_bbox[:, 1] + max_side - 1\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for create PNet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12880 pics in total\n",
      "100 images done, pos: 162 part: 204 neg: 6173\n",
      "200 images done, pos: 490 part: 422 neg: 12337\n",
      "300 images done, pos: 871 part: 801 neg: 18740\n",
      "400 images done, pos: 1206 part: 1160 neg: 25261\n",
      "500 images done, pos: 1546 part: 1537 neg: 31637\n",
      "600 images done, pos: 1756 part: 1875 neg: 37826\n",
      "700 images done, pos: 2141 part: 2232 neg: 44320\n",
      "800 images done, pos: 2588 part: 2766 neg: 50942\n",
      "900 images done, pos: 3183 part: 3384 neg: 57756\n",
      "1000 images done, pos: 3509 part: 3921 neg: 64757\n",
      "finish....\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    2018-10-20 15:50:20\n",
    "    generate positive, negative, positive images whose size are 12*12 and feed into PNet\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import numpy as np\n",
    "\n",
    "prefix = ''\n",
    "anno_file = '../image/anno_train.txt'\n",
    "im_dir = '../image/wider_train/images'\n",
    "pos_save_dir = \"../image/12/positive\"\n",
    "part_save_dir = \"../image/12/part\"\n",
    "neg_save_dir = '../image/12/negative'\n",
    "\n",
    "if not os.path.exists(pos_save_dir):\n",
    "    os.mkdir(pos_save_dir)\n",
    "if not os.path.exists(part_save_dir):\n",
    "    os.mkdir(part_save_dir)\n",
    "if not os.path.exists(neg_save_dir):\n",
    "    os.mkdir(neg_save_dir)\n",
    "\n",
    "# store labels of positive, negative, part images\n",
    "f1 = open(os.path.join('../image/12', 'pos_12.txt'), 'w')\n",
    "f2 = open(os.path.join('../image/12', 'neg_12.txt'), 'w')\n",
    "f3 = open(os.path.join('../image/12', 'part_12.txt'), 'w')\n",
    "\n",
    "# anno_file: store labels of the wider face training data\n",
    "with open(anno_file, 'r') as f:\n",
    "    annotations = f.readlines()\n",
    "num = len(annotations)\n",
    "print(\"%d pics in total\" % num)\n",
    "\n",
    "p_idx = 0 # positive\n",
    "n_idx = 0 # negative\n",
    "d_idx = 0 # dont care\n",
    "idx = 0\n",
    "box_idx = 0\n",
    "\n",
    "for annotation in annotations:\n",
    "    annotation = annotation.strip().split(' ')\n",
    "    im_path = os.path.join(prefix, annotation[0])\n",
    "    #print(im_path)\n",
    "    bbox = list(map(float, annotation[1:]))\n",
    "    boxes = np.array(bbox, dtype=np.int32).reshape(-1, 4)\n",
    "    img = cv2.imread(im_path)\n",
    "    idx += 1\n",
    "    if idx % 3000 == 0:\n",
    "        break\n",
    "    height, width, channel = img.shape\n",
    "\n",
    "    neg_num = 0\n",
    "    while neg_num < 50:\n",
    "        size = np.random.randint(12, min(width, height) / 2)\n",
    "        nx = np.random.randint(0, width - size)\n",
    "        ny = np.random.randint(0, height - size)\n",
    "        crop_box = np.array([nx, ny, nx + size, ny + size])\n",
    "\n",
    "        Iou = IoU(crop_box, boxes)\n",
    "\n",
    "        cropped_im = img[ny: ny + size, nx: nx + size, :]\n",
    "        resized_im = cv2.resize(cropped_im, (12, 12), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        if np.max(Iou) < 0.3:\n",
    "            # Iou with all gts must below 0.3\n",
    "            save_file = os.path.join(neg_save_dir, \"%s.jpg\" % n_idx)\n",
    "            f2.write(save_file + ' 0\\n')\n",
    "            cv2.imwrite(save_file, resized_im)\n",
    "            n_idx += 1\n",
    "            neg_num += 1\n",
    "\n",
    "    for box in boxes:\n",
    "        # box (x_left, y_top, x_right, y_bottom)\n",
    "        x1, y1, w, h = box\n",
    "        # w = x2 - x1 + 1\n",
    "        # h = y2 - y1 + 1\n",
    "        x2 = x1 + w - 1\n",
    "        y2 = y1 + h - 1\n",
    "        # ignore small faces\n",
    "        # in case the ground truth boxes of small faces are not accurate\n",
    "        if max(w, h) < 40 or x1 < 0 or y1 < 0:\n",
    "            continue\n",
    "\n",
    "        # generate negative examples that have overlap with gt\n",
    "        #new_box = [x1,y1,x2,y2]\n",
    "        for i in range(5):\n",
    "            size = np.random.randint(12, min(width, height) / 2)\n",
    "            # delta_x and delta_y are offsets of (x1, y1)\n",
    "\n",
    "            delta_x = np.random.randint(max(-size, -x1), w)\n",
    "            delta_y = np.random.randint(max(-size, -y1), h)\n",
    "            nx1 = max(0, x1 + delta_x)\n",
    "            ny1 = max(0, y1 + delta_y)\n",
    "\n",
    "            if nx1 + size > width or ny1 + size > height:\n",
    "                continue\n",
    "            crop_box = np.array([nx1, ny1, nx1 + size, ny1 + size])\n",
    "            Iou = IoU(crop_box, boxes)\n",
    "            #Iou = IoU(crop_box, new_box)\n",
    "            \n",
    "            cropped_im = img[ny1: ny1 + size, nx1: nx1 + size, :]\n",
    "            resized_im = cv2.resize(cropped_im, (12, 12), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            if np.max(Iou) < 0.3:\n",
    "                # Iou with all gts must below 0.3\n",
    "                save_file = os.path.join(neg_save_dir, \"%s.jpg\" % n_idx)\n",
    "                f2.write(save_file + ' 0\\n')\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "                n_idx += 1\n",
    "\n",
    "        # generate positive examples and part faces\n",
    "        for i in range(20):\n",
    "            size = np.random.randint(int(min(w, h) * 0.8), np.ceil(1.25 * max(w, h)))\n",
    "\n",
    "            # delta here is the offset of box center\n",
    "            delta_x = np.random.randint(-w * 0.2, w * 0.2)\n",
    "            delta_y = np.random.randint(-h * 0.2, h * 0.2)\n",
    "\n",
    "            nx1 = max(x1 + w / 2 + delta_x - size / 2, 0)\n",
    "            ny1 = max(y1 + h / 2 + delta_y - size / 2, 0)\n",
    "            nx2 = nx1 + size\n",
    "            ny2 = ny1 + size\n",
    "\n",
    "            if nx2 > width or ny2 > height:\n",
    "                continue\n",
    "            crop_box = np.array([nx1, ny1, nx2, ny2])\n",
    "\n",
    "            offset_x1 = (x1 - nx1) / float(size)\n",
    "            offset_y1 = (y1 - ny1) / float(size)\n",
    "            offset_x2 = (x2 - nx2) / float(size)\n",
    "            offset_y2 = (y2 - ny2) / float(size)\n",
    "\n",
    "            cropped_im = img[int(ny1): int(ny2), int(nx1): int(nx2), :]\n",
    "            resized_im = cv2.resize(cropped_im, (12, 12), interpolation=cv2.INTER_LINEAR)\n",
    "            box_ = box.reshape(1, -1)\n",
    "            #new_box = np.array([x1, y1, x2, y2])\n",
    "            #box_ = new_box.reshape(1, -1)\n",
    "            if IoU(crop_box, box_) >= 0.65:\n",
    "                save_file = os.path.join(pos_save_dir, \"%s.jpg\" % p_idx)\n",
    "                f1.write(save_file + ' 1 %.2f %.2f %.2f %.2f\\n' % (offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "                #print('postive:',save_file)\n",
    "                p_idx += 1\n",
    "            elif IoU(crop_box, box_) >= 0.4:\n",
    "                save_file = os.path.join(part_save_dir, \"%s.jpg\" % d_idx)\n",
    "                f3.write(save_file + ' -1 %.2f %.2f %.2f %.2f\\n' % (offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "                #print('postive:', save_file)\n",
    "                d_idx += 1\n",
    "        \n",
    "        box_idx += 1\n",
    "        pass\n",
    "    \n",
    "    if idx%100 == 0:\n",
    "        print(\"%s images done, pos: %s part: %s neg: %s\" % (idx, p_idx, d_idx, n_idx))\n",
    "    \n",
    "    pass\n",
    "\n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()\n",
    "\n",
    "print(\"%s images done, pos: %s part: %s neg: %s\" % (idx, p_idx, d_idx, n_idx))\n",
    "\n",
    "print('finish....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "\n",
    "def assemble_data(output_file, anno_file_list=[]):\n",
    "\n",
    "    #assemble the pos, neg, part annotations to one file\n",
    "    size = 12\n",
    "\n",
    "    if len(anno_file_list)==0:\n",
    "        return 0\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    for anno_file in anno_file_list:\n",
    "        with open(anno_file, 'r') as f:\n",
    "            print(anno_file)\n",
    "            anno_lines = f.readlines()\n",
    "\n",
    "        base_num = 250000\n",
    "\n",
    "        if len(anno_lines) > base_num * 3:\n",
    "            idx_keep = npr.choice(len(anno_lines), size=base_num * 3, replace=True)\n",
    "        elif len(anno_lines) > 100000:\n",
    "            idx_keep = npr.choice(len(anno_lines), size=len(anno_lines), replace=True)\n",
    "        else:\n",
    "            idx_keep = np.arange(len(anno_lines))\n",
    "            np.random.shuffle(idx_keep)\n",
    "        chose_count = 0\n",
    "        with open(output_file, 'a+') as f:\n",
    "            for idx in idx_keep:\n",
    "                # write lables of pos, neg, part images\n",
    "                f.write(anno_lines[idx])\n",
    "                chose_count+=1\n",
    "\n",
    "    return chose_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "pnet_postive_file = '../image/12/pos_12.txt'\n",
    "pnet_part_file = '../image/12/part_12.txt'\n",
    "pnet_neg_file = '../image/12/neg_12.txt'\n",
    "pnet_landmark_file = '../image/12/landmark_12.txt'\n",
    "imglist_filename = '../image/12/imglist_anno_12.txt'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    anno_list = []\n",
    "\n",
    "    anno_list.append(pnet_postive_file)\n",
    "    anno_list.append(pnet_part_file)\n",
    "    anno_list.append(pnet_neg_file)\n",
    "    # anno_list.append(pnet_landmark_file)\n",
    "\n",
    "    chose_count = assemble_data(imglist_filename ,anno_list)\n",
    "    print(\"PNet train annotation result file path:%s\" % imglist_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

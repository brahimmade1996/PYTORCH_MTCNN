{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare train data of RNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "#from mtcnn.core.detect import MtcnnDetector,create_mtcnn_net\n",
    "#from tool.imagedb import ImageDB\n",
    "#from tool.imagedb import TestImageLoader\n",
    "import time\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "from tool.utils import convert_to_square,IoU\n",
    "\n",
    "#import mtcnn.config as config\n",
    "\n",
    "#import mtcnn.core.vision as vision\n",
    "\n",
    "prefix_path = ''\n",
    "\n",
    "traindata_store = '../image/train'\n",
    "\n",
    "pnet_model_file = '../model/pnet_epoch.pt'\n",
    "\n",
    "annotation_file = '../image/anno_train_test.txt'\n",
    "\n",
    "use_cuda = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rnet_data(data_dir, anno_file, pnet_model_file, prefix_path='', use_cuda=True, vis=False):\n",
    "\n",
    "    \"\"\"\n",
    "    :param data_dir: train data\n",
    "    :param anno_file:\n",
    "    :param pnet_model_file:\n",
    "    :param prefix_path:\n",
    "    :param use_cuda:\n",
    "    :param vis:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # load trained pnet model\n",
    "    pnet, _, _ = create_mtcnn_net(p_model_path=pnet_model_file, use_cuda=use_cuda)\n",
    "    mtcnn_detector = MtcnnDetector(pnet=pnet,min_face_size=12)\n",
    "\n",
    "    # load original_anno_file, length = 12880\n",
    "    imagedb = ImageDB(anno_file,mode=\"test\",prefix_path=prefix_path)\n",
    "    imdb = imagedb.load_imdb()\n",
    "    image_reader = TestImageLoader(imdb,1,False)\n",
    "\n",
    "    all_boxes = list()\n",
    "    batch_idx = 0\n",
    "\n",
    "    print('size:%d' %image_reader.size)\n",
    "    for databatch in image_reader:\n",
    "        if batch_idx % 100 == 0:\n",
    "            print (\"%d images done\" % batch_idx)\n",
    "        im = databatch\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # obtain boxes and aligned boxes\n",
    "        boxes, boxes_align = mtcnn_detector.detect_pnet(im=im)\n",
    "        if boxes_align is None:\n",
    "            all_boxes.append(np.array([]))\n",
    "            batch_idx += 1\n",
    "            continue\n",
    "        if vis:\n",
    "            rgb_im = cv2.cvtColor(np.asarray(im), cv2.COLOR_BGR2RGB)\n",
    "            vision.vis_two(rgb_im, boxes, boxes_align)\n",
    "\n",
    "        t1 = time.time() - t\n",
    "        t = time.time()\n",
    "        all_boxes.append(boxes_align)\n",
    "        batch_idx += 1\n",
    "        # if batch_idx == 100:\n",
    "            # break\n",
    "        # print(\"shape of all boxes {0}\".format(all_boxes))\n",
    "        # time.sleep(5)\n",
    "\n",
    "    # save_path = model_store_path()\n",
    "    # './model_store'\n",
    "    save_path = './model_store'\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    save_file = os.path.join(save_path, \"detections_%d.pkl\" % int(time.time()))\n",
    "    with open(save_file, 'wb') as f:\n",
    "        cPickle.dump(all_boxes, f, cPickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    gen_rnet_sample_data(data_dir, anno_file, save_file, prefix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rnet_sample_data(data_dir, anno_file, det_boxs_file, prefix_path):\n",
    "\n",
    "    \"\"\"\n",
    "    :param data_dir:\n",
    "    :param anno_file: original annotations file of wider face data\n",
    "    :param det_boxs_file: detection boxes file\n",
    "    :param prefix_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    neg_save_dir = os.path.join(data_dir, \"24/negative\")\n",
    "    pos_save_dir = os.path.join(data_dir, \"24/positive\")\n",
    "    part_save_dir = os.path.join(data_dir, \"24/part\")\n",
    "\n",
    "\n",
    "    for dir_path in [neg_save_dir, pos_save_dir, part_save_dir]:\n",
    "        # print(dir_path)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "\n",
    "    # load ground truth from annotation file\n",
    "    # format of each line: image/path [x1,y1,x2,y2] for each gt_box in this image\n",
    "\n",
    "    with open(anno_file, 'r') as f:\n",
    "        annotations = f.readlines()\n",
    "\n",
    "    image_size = 24\n",
    "    net = \"rnet\"\n",
    "\n",
    "    im_idx_list = list()\n",
    "    gt_boxes_list = list()\n",
    "    num_of_images = len(annotations)\n",
    "    print (\"processing %d images in total\" % num_of_images)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        annotation = annotation.strip().split(' ')\n",
    "        im_idx = os.path.join(prefix_path,annotation[0])\n",
    "        # im_idx = annotation[0]\n",
    "\n",
    "        boxes = list(map(float, annotation[1:]))\n",
    "        boxes = np.array(boxes, dtype=np.float32).reshape(-1, 4)\n",
    "        im_idx_list.append(im_idx)\n",
    "        gt_boxes_list.append(boxes)\n",
    "\n",
    "\n",
    "    # './anno_store'\n",
    "    save_path = './anno_store'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    f1 = open(os.path.join(save_path, 'pos_%d.txt' % image_size), 'w')\n",
    "    f2 = open(os.path.join(save_path, 'neg_%d.txt' % image_size), 'w')\n",
    "    f3 = open(os.path.join(save_path, 'part_%d.txt' % image_size), 'w')\n",
    "\n",
    "    # print(det_boxs_file)\n",
    "    det_handle = open(det_boxs_file, 'rb')\n",
    "\n",
    "    det_boxes = cPickle.load(det_handle)\n",
    "\n",
    "    # an image contain many boxes stored in an array\n",
    "    print(len(det_boxes), num_of_images)\n",
    "    # assert len(det_boxes) == num_of_images, \"incorrect detections or ground truths\"\n",
    "\n",
    "    # index of neg, pos and part face, used as their image names\n",
    "    n_idx = 0\n",
    "    p_idx = 0\n",
    "    d_idx = 0\n",
    "    image_done = 0\n",
    "    for im_idx, dets, gts in zip(im_idx_list, det_boxes, gt_boxes_list):\n",
    "\n",
    "        # if (im_idx+1) == 100:\n",
    "            # break\n",
    "\n",
    "        gts = np.array(gts, dtype=np.float32).reshape(-1, 4)\n",
    "        if image_done % 100 == 0:\n",
    "            print(\"%d images done\" % image_done)\n",
    "        image_done += 1\n",
    "\n",
    "        if dets.shape[0] == 0:\n",
    "            continue\n",
    "        img = cv2.imread(im_idx)\n",
    "        # change to square\n",
    "        dets = convert_to_square(dets)\n",
    "        dets[:, 0:4] = np.round(dets[:, 0:4])\n",
    "        neg_num = 0\n",
    "        for box in dets:\n",
    "            x_left, y_top, x_right, y_bottom, _ = box.astype(int)\n",
    "            width = x_right - x_left + 1\n",
    "            height = y_bottom - y_top + 1\n",
    "\n",
    "            # ignore box that is too small or beyond image border\n",
    "            if width < 20 or x_left < 0 or y_top < 0 or x_right > img.shape[1] - 1 or y_bottom > img.shape[0] - 1:\n",
    "                continue\n",
    "\n",
    "            # compute intersection over union(IoU) between current box and all gt boxes\n",
    "            Iou = IoU(box, gts)\n",
    "            cropped_im = img[y_top:y_bottom + 1, x_left:x_right + 1, :]\n",
    "            resized_im = cv2.resize(cropped_im, (image_size, image_size),\n",
    "                                    interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # save negative images and write label\n",
    "            # Iou with all gts must below 0.3\n",
    "            if np.max(Iou) < 0.3 and neg_num < 60:\n",
    "                # save the examples\n",
    "                save_file = os.path.join(neg_save_dir, \"%s.jpg\" % n_idx)\n",
    "                # print(save_file)\n",
    "                f2.write(save_file + ' 0\\n')\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "                n_idx += 1\n",
    "                neg_num += 1\n",
    "            else:\n",
    "                # find gt_box with the highest iou\n",
    "                idx = np.argmax(Iou)\n",
    "                assigned_gt = gts[idx]\n",
    "                x1, y1, x2, y2 = assigned_gt\n",
    "\n",
    "                # compute bbox reg label\n",
    "                offset_x1 = (x1 - x_left) / float(width)\n",
    "                offset_y1 = (y1 - y_top) / float(height)\n",
    "                offset_x2 = (x2 - x_right) / float(width)\n",
    "                offset_y2 = (y2 - y_bottom) / float(height)\n",
    "\n",
    "                # save positive and part-face images and write labels\n",
    "                if np.max(Iou) >= 0.65:\n",
    "                    save_file = os.path.join(pos_save_dir, \"%s.jpg\" % p_idx)\n",
    "                    f1.write(save_file + ' 1 %.2f %.2f %.2f %.2f\\n' % (\n",
    "                        offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                    cv2.imwrite(save_file, resized_im)\n",
    "                    p_idx += 1\n",
    "\n",
    "                elif np.max(Iou) >= 0.4:\n",
    "                    save_file = os.path.join(part_save_dir, \"%s.jpg\" % d_idx)\n",
    "                    f3.write(save_file + ' -1 %.2f %.2f %.2f %.2f\\n' % (\n",
    "                        offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                    cv2.imwrite(save_file, resized_im)\n",
    "                    d_idx += 1\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f3.close()\n",
    "\n",
    "def model_store_path():\n",
    "    return os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))+\"/model_store\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    gen_rnet_data(traindata_store, annotation_file, pnet_model_file, prefix_path, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练PNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8875, -1.8204,  0.9606, -0.4746])\n",
      "torch.Size([4, 3, 12, 12])\n",
      "b tensor([0.5551, 0.5520, 0.5659, 0.5395], grad_fn=<SqueezeBackward0>)\n",
      "a: tensor([True, True, True, True])\n",
      "c tensor([0.5551, 0.5520, 0.5659, 0.5395], grad_fn=<MaskedSelectBackward>)\n",
      "c tensor([True, True, True, True])\n",
      "tensor([-0.6575, -1.0597,  1.4862, -0.6248])\n",
      "torch.Size([4, 3, 12, 12])\n",
      "b tensor([0.5767, 0.5802, 0.5421, 0.5395], grad_fn=<SqueezeBackward0>)\n",
      "a: tensor([True, True, True, True])\n",
      "c tensor([0.5767, 0.5802, 0.5421, 0.5395], grad_fn=<MaskedSelectBackward>)\n",
      "c tensor([True, True, True, True])\n",
      "Rnet out label shape: torch.Size([4, 2])\n",
      "Rnet out offset shape: torch.Size([4, 4])\n",
      "a torch.Size([4, 2])\n",
      "torch.Size([4, 3, 48, 48])\n",
      "Rnet out label shape: torch.Size([4, 2])\n",
      "Rnet out offset shape: torch.Size([4, 4])\n",
      "Rnet out offset shape: torch.Size([4, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysf46\\anaconda3\\envs\\SEED_AI\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x206f84b0d88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入公共文件\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# add other package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tool.plotcm import plot_confusion_matrix\n",
    "\n",
    "import pdb\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "#torch.set_printoptions(linewidth=120)\n",
    "\n",
    "from mtcnn.PNet import PNet\n",
    "\n",
    "from mtcnn.mtcnn import RunBuilder\n",
    "\n",
    "from mtcnn.LossFn import LossFn\n",
    "\n",
    "from tool.imagedb import ImageDB\n",
    "\n",
    "from tool.imagedb import TrainImageReader\n",
    "\n",
    "from tool import image_tools\n",
    "\n",
    "import datetime\n",
    "\n",
    "torch.set_grad_enabled(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(prob_cls, gt_cls):\n",
    "\n",
    "    prob_cls = torch.squeeze(prob_cls)\n",
    "    \n",
    "    gt_cls = torch.squeeze(gt_cls)\n",
    "\n",
    "    #we only need the detection which >= 0\n",
    "    mask = torch.ge(gt_cls,0)\n",
    "    #get valid element\n",
    "    valid_gt_cls = torch.masked_select(gt_cls,mask)\n",
    "    \n",
    "    valid_prob_cls = torch.masked_select(prob_cls,mask)\n",
    "    \n",
    "    size = min(valid_gt_cls.size()[0], valid_prob_cls.size()[0])\n",
    "    \n",
    "    prob_ones = torch.ge(valid_prob_cls,0.6).float()\n",
    "    \n",
    "    right_ones = torch.eq(prob_ones,valid_gt_cls).float()\n",
    "    \n",
    "    #cms = confusion_matrix(prob_ones,right_ones,[0,1])\n",
    "    \n",
    "    #print(cms)\n",
    "    \n",
    "    #names = ('0','1')\n",
    "    \n",
    "    #plot_confusion_matrix(cms, names)\n",
    "    \n",
    "    #print(prob_cls.shape,gt_cls.shape,valid_prob_cls.shape,right_ones.shape)\n",
    "\n",
    "    ## if size == 0 meaning that your gt_labels are all negative, landmark or part\n",
    "    return torch.div(torch.mul(torch.sum(right_ones),float(1.0)),float(size)) \n",
    "    ## divided by zero meaning that your gt_labels are all negative, landmark or part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation_file = './image/imglist_anno_12.txt'\n",
    "annotation_file  = '../image/12/imglist_anno_12.txt' #'./image/wider_face/wider_face_train_bbx_gt.txt' #'./image/anno_train.txt'\n",
    "\n",
    "model_store_path = '../model/Pnet'\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [2000]\n",
    "    #,device = [\"cuda\", \"cpu\"]\n",
    "    ,shuffle = [True]\n",
    ")\n",
    "\n",
    "end_epoch = 10\n",
    "\n",
    "frequent = 10\n",
    "\n",
    "#runs = RunBuilder.get_runs(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(imdb=None):\n",
    "    \n",
    "    if imdb == None:\n",
    "        imagedb = ImageDB(annotation_file)\n",
    "        imdb = imagedb.load_imdb()\n",
    "        #print(imdb.num_images)\n",
    "        imdb = imagedb.append_flipped_images(imdb)\n",
    "    \n",
    "    for run in RunBuilder.get_runs(params):\n",
    "        #create model path\n",
    "        if not os.path.exists(model_store_path):\n",
    "            os.makedirs(model_store_path)\n",
    "            \n",
    "        #create data_loader\n",
    "        train_data=TrainImageReader(imdb,12,batch_size=run.batch_size,shuffle=run.shuffle)\n",
    "        \n",
    "        #print(train_data.data[0].shape,len(train_data.data))\n",
    "        #Sprint(train_data.label[0][0])\n",
    "        \n",
    "        acc=0.0\n",
    "        \n",
    "        comment = f'-{run}'\n",
    "        \n",
    "        lossfn = LossFn()\n",
    "        \n",
    "        network = PNet()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(network.parameters(), lr=run.lr)\n",
    "        \n",
    "        for epoch in range(end_epoch):\n",
    "            train_data.reset() # shuffle\n",
    "            epoch_acc = 0.0\n",
    "            #for batch_idx,(image,(gt_label,gt_bbox,gt_landmark))in enumerate(train_dat)\n",
    "            for batch_idx,(image,(gt_label,gt_bbox,gt_landmark))in enumerate(train_data):\n",
    "                \n",
    "                im_tensor = [ image_tools.convert_image_to_tensor(image[i,:,:,:]) for i in range(image.shape[0]) ]\n",
    "                im_tensor = torch.stack(im_tensor)\n",
    "\n",
    "                im_tensor = Variable(im_tensor)\n",
    "                gt_label = Variable(torch.from_numpy(gt_label).float())\n",
    "\n",
    "                gt_bbox = Variable(torch.from_numpy(gt_bbox).float())\n",
    "                #gt_landmark = Variable(torch.from_numpy(gt_landmark).float())\n",
    "                \n",
    "                cls_pred, box_offset_pred = network(im_tensor)\n",
    "                \n",
    "                cls_loss = lossfn.cls_loss(gt_label,cls_pred)\n",
    "                \n",
    "                box_offset_loss = lossfn.box_loss(gt_label,gt_bbox,box_offset_pred)\n",
    "                \n",
    "                all_loss = cls_loss*1.0+box_offset_loss*0.5\n",
    "                \n",
    "                if batch_idx%frequent==0:\n",
    "                    accuracy=compute_accuracy(cls_pred,gt_label)\n",
    "                    accuracy=compute_accuracy(cls_pred,gt_label)\n",
    "                    show1 = accuracy.data.cpu().numpy()\n",
    "                    show2 = cls_loss.data.cpu().numpy()\n",
    "                    show3 = box_offset_loss.data.cpu().numpy()\n",
    "                    # show4 = landmark_loss.data.cpu().numpy()\n",
    "                    show5 = all_loss.data.cpu().numpy()\n",
    "                    print(\"%s : Epoch: %d, Step: %d, accuracy: %s, det loss: %s, bbox loss: %s, all_loss: %s, lr:%s \"%\n",
    "                          (datetime.datetime.now(),epoch,batch_idx, show1,show2,show3,show5,run.lr))\n",
    "                    epoch_acc = show1\n",
    "                #计算偏差矩阵\n",
    "                optimizer.zero_grad()\n",
    "                all_loss.backward()\n",
    "                optimizer.step()\n",
    "                pass\n",
    "            \n",
    "            pass \n",
    "            print('save modle acc:', epoch_acc)\n",
    "            torch.save(network.state_dict(), os.path.join(model_store_path,\"pnet_epoch_%d.pt\" % epoch))\n",
    "            torch.save(network, os.path.join(model_store_path,\"pnet_epoch_model_%d.pkl\" % epoch))\n",
    "        pass\n",
    "        \n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Pnet Process:...\n",
      "append flipped images to imdb 72129\n",
      "2020-05-21 23:53:50.921667 : Epoch: 0, Step: 0, accuracy: 0.57535696, det loss: 0.88428044, bbox loss: 0.18741345, all_loss: 0.9779872, lr:0.01 \n",
      "2020-05-21 23:53:59.577856 : Epoch: 0, Step: 10, accuracy: 0.94787234, det loss: 0.18041657, bbox loss: 0.046751834, all_loss: 0.20379248, lr:0.01 \n",
      "2020-05-21 23:54:08.230471 : Epoch: 0, Step: 20, accuracy: 0.95137423, det loss: 0.16063786, bbox loss: 0.036383662, all_loss: 0.17882968, lr:0.01 \n",
      "2020-05-21 23:54:17.165781 : Epoch: 0, Step: 30, accuracy: 0.95741326, det loss: 0.14517276, bbox loss: 0.039338004, all_loss: 0.16484176, lr:0.01 \n",
      "2020-05-21 23:54:25.829193 : Epoch: 0, Step: 40, accuracy: 0.9542827, det loss: 0.15249781, bbox loss: 0.040936694, all_loss: 0.17296615, lr:0.01 \n",
      "2020-05-21 23:54:34.305235 : Epoch: 0, Step: 50, accuracy: 0.95531917, det loss: 0.14326507, bbox loss: 0.047609273, all_loss: 0.1670697, lr:0.01 \n",
      "2020-05-21 23:54:42.793345 : Epoch: 0, Step: 60, accuracy: 0.9514512, det loss: 0.1465687, bbox loss: 0.03774166, all_loss: 0.16543953, lr:0.01 \n",
      "2020-05-21 23:54:51.226672 : Epoch: 0, Step: 70, accuracy: 0.94736844, det loss: 0.14733544, bbox loss: 0.03899685, all_loss: 0.16683386, lr:0.01 \n",
      "save modle acc: 0.94736844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysf46\\anaconda3\\envs\\SEED_AI\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type PNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\ysf46\\anaconda3\\envs\\SEED_AI\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 23:54:52.960092 : Epoch: 1, Step: 0, accuracy: 0.95029086, det loss: 0.14584081, bbox loss: 0.037043568, all_loss: 0.1643626, lr:0.01 \n",
      "2020-05-21 23:55:01.480410 : Epoch: 1, Step: 10, accuracy: 0.95120674, det loss: 0.13277407, bbox loss: 0.04400578, all_loss: 0.15477696, lr:0.01 \n",
      "2020-05-21 23:55:09.931000 : Epoch: 1, Step: 20, accuracy: 0.94992095, det loss: 0.13991153, bbox loss: 0.05287929, all_loss: 0.16635117, lr:0.01 \n",
      "2020-05-21 23:55:18.400398 : Epoch: 1, Step: 30, accuracy: 0.94542533, det loss: 0.14350383, bbox loss: 0.04011019, all_loss: 0.16355893, lr:0.01 \n",
      "2020-05-21 23:55:26.939178 : Epoch: 1, Step: 40, accuracy: 0.9507154, det loss: 0.14034882, bbox loss: 0.044996437, all_loss: 0.16284704, lr:0.01 \n",
      "2020-05-21 23:55:35.494966 : Epoch: 1, Step: 50, accuracy: 0.95270985, det loss: 0.13824528, bbox loss: 0.035163894, all_loss: 0.15582722, lr:0.01 \n",
      "2020-05-21 23:55:44.046275 : Epoch: 1, Step: 60, accuracy: 0.94385594, det loss: 0.13874175, bbox loss: 0.039140128, all_loss: 0.15831181, lr:0.01 \n",
      "2020-05-21 23:55:52.517972 : Epoch: 1, Step: 70, accuracy: 0.9453781, det loss: 0.1312378, bbox loss: 0.038483433, all_loss: 0.15047953, lr:0.01 \n",
      "save modle acc: 0.9453781\n",
      "2020-05-21 23:55:54.222451 : Epoch: 2, Step: 0, accuracy: 0.9435654, det loss: 0.1295438, bbox loss: 0.033749986, all_loss: 0.1464188, lr:0.01 \n",
      "2020-05-21 23:56:02.976881 : Epoch: 2, Step: 10, accuracy: 0.947983, det loss: 0.12934412, bbox loss: 0.04731099, all_loss: 0.15299961, lr:0.01 \n",
      "2020-05-21 23:56:11.998250 : Epoch: 2, Step: 20, accuracy: 0.9420829, det loss: 0.12689325, bbox loss: 0.03826662, all_loss: 0.14602657, lr:0.01 \n",
      "2020-05-21 23:56:20.751536 : Epoch: 2, Step: 30, accuracy: 0.9445032, det loss: 0.13908501, bbox loss: 0.03526323, all_loss: 0.15671663, lr:0.01 \n",
      "2020-05-21 23:56:29.257781 : Epoch: 2, Step: 40, accuracy: 0.94706196, det loss: 0.12923859, bbox loss: 0.037983898, all_loss: 0.14823054, lr:0.01 \n",
      "2020-05-21 23:56:37.781857 : Epoch: 2, Step: 50, accuracy: 0.94470775, det loss: 0.12313747, bbox loss: 0.03395065, all_loss: 0.14011279, lr:0.01 \n",
      "2020-05-21 23:56:46.203612 : Epoch: 2, Step: 60, accuracy: 0.9539439, det loss: 0.117513284, bbox loss: 0.03331942, all_loss: 0.13417299, lr:0.01 \n",
      "2020-05-21 23:56:54.750484 : Epoch: 2, Step: 70, accuracy: 0.9537086, det loss: 0.12595794, bbox loss: 0.045828287, all_loss: 0.14887208, lr:0.01 \n",
      "save modle acc: 0.9537086\n",
      "2020-05-21 23:56:56.447323 : Epoch: 3, Step: 0, accuracy: 0.94899046, det loss: 0.12685795, bbox loss: 0.03870731, all_loss: 0.14621161, lr:0.01 \n",
      "2020-05-21 23:57:04.935583 : Epoch: 3, Step: 10, accuracy: 0.9587131, det loss: 0.10286199, bbox loss: 0.035060614, all_loss: 0.1203923, lr:0.01 \n",
      "2020-05-21 23:57:13.385955 : Epoch: 3, Step: 20, accuracy: 0.9541139, det loss: 0.1293417, bbox loss: 0.034029454, all_loss: 0.14635643, lr:0.01 \n",
      "2020-05-21 23:57:21.848833 : Epoch: 3, Step: 30, accuracy: 0.9451187, det loss: 0.12656361, bbox loss: 0.03596056, all_loss: 0.14454389, lr:0.01 \n",
      "2020-05-21 23:57:30.302189 : Epoch: 3, Step: 40, accuracy: 0.9517241, det loss: 0.11620034, bbox loss: 0.039050918, all_loss: 0.1357258, lr:0.01 \n",
      "2020-05-21 23:57:38.819158 : Epoch: 3, Step: 50, accuracy: 0.95351297, det loss: 0.121837094, bbox loss: 0.052067135, all_loss: 0.14787066, lr:0.01 \n",
      "2020-05-21 23:57:47.327296 : Epoch: 3, Step: 60, accuracy: 0.943038, det loss: 0.12144508, bbox loss: 0.05006457, all_loss: 0.14647737, lr:0.01 \n",
      "2020-05-21 23:57:55.826368 : Epoch: 3, Step: 70, accuracy: 0.9508976, det loss: 0.12508276, bbox loss: 0.037116744, all_loss: 0.14364113, lr:0.01 \n",
      "save modle acc: 0.9508976\n",
      "2020-05-21 23:57:57.538340 : Epoch: 4, Step: 0, accuracy: 0.9521505, det loss: 0.12788437, bbox loss: 0.039505202, all_loss: 0.14763698, lr:0.01 \n",
      "2020-05-21 23:58:06.322956 : Epoch: 4, Step: 10, accuracy: 0.9504742, det loss: 0.114103384, bbox loss: 0.044014525, all_loss: 0.13611065, lr:0.01 \n",
      "2020-05-21 23:58:15.058326 : Epoch: 4, Step: 20, accuracy: 0.9530591, det loss: 0.108055815, bbox loss: 0.039430242, all_loss: 0.12777093, lr:0.01 \n",
      "2020-05-21 23:58:23.684867 : Epoch: 4, Step: 30, accuracy: 0.959596, det loss: 0.11387299, bbox loss: 0.04072903, all_loss: 0.1342375, lr:0.01 \n",
      "2020-05-21 23:58:32.254803 : Epoch: 4, Step: 40, accuracy: 0.96317726, det loss: 0.10021861, bbox loss: 0.043513756, all_loss: 0.12197549, lr:0.01 \n",
      "2020-05-21 23:58:40.849286 : Epoch: 4, Step: 50, accuracy: 0.9487983, det loss: 0.13290134, bbox loss: 0.043081574, all_loss: 0.15444213, lr:0.01 \n",
      "2020-05-21 23:58:49.820317 : Epoch: 4, Step: 60, accuracy: 0.95815676, det loss: 0.1072938, bbox loss: 0.045001, all_loss: 0.1297943, lr:0.01 \n",
      "2020-05-21 23:58:58.510567 : Epoch: 4, Step: 70, accuracy: 0.9505582, det loss: 0.13850325, bbox loss: 0.041927412, all_loss: 0.15946695, lr:0.01 \n",
      "save modle acc: 0.9505582\n",
      "2020-05-21 23:59:00.243933 : Epoch: 5, Step: 0, accuracy: 0.95243126, det loss: 0.122225575, bbox loss: 0.03768737, all_loss: 0.14106926, lr:0.01 \n",
      "2020-05-21 23:59:09.226631 : Epoch: 5, Step: 10, accuracy: 0.9628844, det loss: 0.10018518, bbox loss: 0.040256742, all_loss: 0.12031355, lr:0.01 \n",
      "2020-05-21 23:59:18.351712 : Epoch: 5, Step: 20, accuracy: 0.9498681, det loss: 0.12767608, bbox loss: 0.049052134, all_loss: 0.15220216, lr:0.01 \n",
      "2020-05-21 23:59:26.935761 : Epoch: 5, Step: 30, accuracy: 0.96629804, det loss: 0.07945833, bbox loss: 0.030075608, all_loss: 0.09449614, lr:0.01 \n",
      "2020-05-21 23:59:35.682322 : Epoch: 5, Step: 40, accuracy: 0.962845, det loss: 0.097484306, bbox loss: 0.037755106, all_loss: 0.11636186, lr:0.01 \n",
      "2020-05-21 23:59:44.415336 : Epoch: 5, Step: 50, accuracy: 0.95182014, det loss: 0.12885934, bbox loss: 0.030646566, all_loss: 0.14418262, lr:0.01 \n",
      "2020-05-21 23:59:52.770781 : Epoch: 5, Step: 60, accuracy: 0.962533, det loss: 0.09196509, bbox loss: 0.03702216, all_loss: 0.110476166, lr:0.01 \n",
      "2020-05-22 00:00:01.340632 : Epoch: 5, Step: 70, accuracy: 0.9532412, det loss: 0.11351157, bbox loss: 0.036016405, all_loss: 0.13151976, lr:0.01 \n",
      "save modle acc: 0.9532412\n",
      "2020-05-22 00:00:03.033970 : Epoch: 6, Step: 0, accuracy: 0.96522653, det loss: 0.09398774, bbox loss: 0.042253863, all_loss: 0.115114674, lr:0.01 \n",
      "2020-05-22 00:00:11.715936 : Epoch: 6, Step: 10, accuracy: 0.957301, det loss: 0.102863535, bbox loss: 0.034364056, all_loss: 0.120045565, lr:0.01 \n",
      "2020-05-22 00:00:20.672636 : Epoch: 6, Step: 20, accuracy: 0.9526344, det loss: 0.11528875, bbox loss: 0.03064112, all_loss: 0.1306093, lr:0.01 \n",
      "2020-05-22 00:00:29.811799 : Epoch: 6, Step: 30, accuracy: 0.96048474, det loss: 0.10538814, bbox loss: 0.04239977, all_loss: 0.12658803, lr:0.01 \n",
      "2020-05-22 00:00:38.680242 : Epoch: 6, Step: 40, accuracy: 0.9593238, det loss: 0.104410715, bbox loss: 0.02926558, all_loss: 0.11904351, lr:0.01 \n",
      "2020-05-22 00:00:47.241816 : Epoch: 6, Step: 50, accuracy: 0.9537329, det loss: 0.11352033, bbox loss: 0.040586807, all_loss: 0.13381374, lr:0.01 \n",
      "2020-05-22 00:00:55.920154 : Epoch: 6, Step: 60, accuracy: 0.9536247, det loss: 0.12778147, bbox loss: 0.03526809, all_loss: 0.14541551, lr:0.01 \n",
      "2020-05-22 00:01:04.882603 : Epoch: 6, Step: 70, accuracy: 0.958682, det loss: 0.11648745, bbox loss: 0.03144077, all_loss: 0.13220784, lr:0.01 \n",
      "save modle acc: 0.958682\n",
      "2020-05-22 00:01:06.578154 : Epoch: 7, Step: 0, accuracy: 0.9583333, det loss: 0.10799468, bbox loss: 0.03590721, all_loss: 0.12594828, lr:0.01 \n",
      "2020-05-22 00:01:15.616275 : Epoch: 7, Step: 10, accuracy: 0.95726496, det loss: 0.10759765, bbox loss: 0.030095462, all_loss: 0.12264538, lr:0.01 \n",
      "2020-05-22 00:01:24.930128 : Epoch: 7, Step: 20, accuracy: 0.9606712, det loss: 0.11151961, bbox loss: 0.040468384, all_loss: 0.1317538, lr:0.01 \n",
      "2020-05-22 00:01:33.976942 : Epoch: 7, Step: 30, accuracy: 0.9620929, det loss: 0.09788823, bbox loss: 0.034742817, all_loss: 0.11525964, lr:0.01 \n",
      "2020-05-22 00:01:42.891110 : Epoch: 7, Step: 40, accuracy: 0.962533, det loss: 0.097664006, bbox loss: 0.0378979, all_loss: 0.116612956, lr:0.01 \n",
      "2020-05-22 00:01:51.462683 : Epoch: 7, Step: 50, accuracy: 0.95435464, det loss: 0.112005964, bbox loss: 0.035971, all_loss: 0.12999147, lr:0.01 \n",
      "2020-05-22 00:01:59.914215 : Epoch: 7, Step: 60, accuracy: 0.9584866, det loss: 0.11046446, bbox loss: 0.03412474, all_loss: 0.12752683, lr:0.01 \n",
      "2020-05-22 00:02:08.393557 : Epoch: 7, Step: 70, accuracy: 0.9542827, det loss: 0.11065249, bbox loss: 0.036587477, all_loss: 0.12894623, lr:0.01 \n",
      "save modle acc: 0.9542827\n",
      "2020-05-22 00:02:10.064855 : Epoch: 8, Step: 0, accuracy: 0.9577766, det loss: 0.11844517, bbox loss: 0.039615914, all_loss: 0.13825312, lr:0.01 \n",
      "2020-05-22 00:02:18.490655 : Epoch: 8, Step: 10, accuracy: 0.9596603, det loss: 0.104776345, bbox loss: 0.038543727, all_loss: 0.12404821, lr:0.01 \n",
      "2020-05-22 00:02:27.001944 : Epoch: 8, Step: 20, accuracy: 0.9598521, det loss: 0.10257063, bbox loss: 0.03825978, all_loss: 0.12170052, lr:0.01 \n",
      "2020-05-22 00:02:35.435880 : Epoch: 8, Step: 30, accuracy: 0.96339524, det loss: 0.09657318, bbox loss: 0.039003715, all_loss: 0.11607504, lr:0.01 \n",
      "2020-05-22 00:02:43.902107 : Epoch: 8, Step: 40, accuracy: 0.9560381, det loss: 0.10826932, bbox loss: 0.05182286, all_loss: 0.13418075, lr:0.01 \n",
      "2020-05-22 00:02:52.342492 : Epoch: 8, Step: 50, accuracy: 0.95894736, det loss: 0.11005133, bbox loss: 0.04258126, all_loss: 0.13134196, lr:0.01 \n",
      "2020-05-22 00:03:00.803416 : Epoch: 8, Step: 60, accuracy: 0.9637415, det loss: 0.10014651, bbox loss: 0.030851638, all_loss: 0.115572326, lr:0.01 \n",
      "2020-05-22 00:03:09.259702 : Epoch: 8, Step: 70, accuracy: 0.9567282, det loss: 0.11076134, bbox loss: 0.034227666, all_loss: 0.12787516, lr:0.01 \n",
      "save modle acc: 0.9567282\n",
      "2020-05-22 00:03:10.963047 : Epoch: 9, Step: 0, accuracy: 0.9640782, det loss: 0.079665974, bbox loss: 0.03785787, all_loss: 0.09859491, lr:0.01 \n",
      "2020-05-22 00:03:19.474295 : Epoch: 9, Step: 10, accuracy: 0.9691161, det loss: 0.08741643, bbox loss: 0.03525629, all_loss: 0.10504457, lr:0.01 \n",
      "2020-05-22 00:03:27.962330 : Epoch: 9, Step: 20, accuracy: 0.95372343, det loss: 0.11006288, bbox loss: 0.043605246, all_loss: 0.1318655, lr:0.01 \n",
      "2020-05-22 00:03:36.466836 : Epoch: 9, Step: 30, accuracy: 0.9502357, det loss: 0.11467133, bbox loss: 0.046543512, all_loss: 0.13794309, lr:0.01 \n",
      "2020-05-22 00:03:45.093308 : Epoch: 9, Step: 40, accuracy: 0.9667371, det loss: 0.09515668, bbox loss: 0.047248714, all_loss: 0.11878103, lr:0.01 \n",
      "2020-05-22 00:03:53.693463 : Epoch: 9, Step: 50, accuracy: 0.9571882, det loss: 0.108233236, bbox loss: 0.042235512, all_loss: 0.12935099, lr:0.01 \n",
      "2020-05-22 00:04:02.332743 : Epoch: 9, Step: 60, accuracy: 0.9666843, det loss: 0.09887517, bbox loss: 0.034468915, all_loss: 0.11610963, lr:0.01 \n",
      "2020-05-22 00:04:11.042830 : Epoch: 9, Step: 70, accuracy: 0.9566596, det loss: 0.10612261, bbox loss: 0.03652705, all_loss: 0.12438614, lr:0.01 \n",
      "save modle acc: 0.9566596\n",
      "finish....\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('train Pnet Process:...')\n",
    "    #加载图片文件\n",
    "    #imagedb = ImageDB(annotation_file,'./image/train')\n",
    "    #gt_imdb = imagedb.load_imdb()\n",
    "    #gt_imdb = imagedb.append_flipped_images(gt_imdb)\n",
    "    train_net()\n",
    "    \n",
    "    print('finish....')\n",
    "    #print(gt_imdb[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

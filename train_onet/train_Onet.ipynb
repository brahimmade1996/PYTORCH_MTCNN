{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1a34ae90b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入公共文件\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# add other package\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tool.plotcm import plot_confusion_matrix\n",
    "\n",
    "import pdb\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "#torch.set_printoptions(linewidth=120)\n",
    "\n",
    "from mtcnn.ONet import ONet\n",
    "\n",
    "from mtcnn.mtcnn import RunBuilder\n",
    "\n",
    "from mtcnn.LossFn import LossFn\n",
    "\n",
    "from tool.imagedb import ImageDB\n",
    "\n",
    "from tool.imagedb import TrainImageReader\n",
    "\n",
    "from tool import image_tools\n",
    "\n",
    "import datetime\n",
    "\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = \"../image/48/imglist_anno_48.txt\"\n",
    "model_store_path = \"../model\"\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [2000]\n",
    "    ,device = [\"cpu\"]\n",
    "    ,shuffle = [True]\n",
    ")\n",
    "\n",
    "end_epoch = 10\n",
    "\n",
    "frequent = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_onet(imdb=None):\n",
    "    \n",
    "    if imdb == None:\n",
    "        imagedb = ImageDB(annotation_file)\n",
    "        imdb = imagedb.load_imdb()\n",
    "        #print(imdb.num_images)\n",
    "        imdb = imagedb.append_flipped_images(imdb)\n",
    "        \n",
    "    for run in RunBuilder.get_runs(params):\n",
    "        use_cuda= True if run.device == 'cuda' else False\n",
    "        #create model path\n",
    "        if not os.path.exists(model_store_path):\n",
    "            os.makedirs(model_store_path)\n",
    "        \n",
    "        lossfn = LossFn()\n",
    "        \n",
    "        network = ONet(is_train=True, use_cuda=use_cuda)\n",
    "        \n",
    "        if use_cuda:\n",
    "            network.cuda()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(network.parameters(), lr=run.lr)\n",
    "        \n",
    "        train_data=TrainImageReader(imdb,24,run.batch_size,shuffle=True)\n",
    "        \n",
    "        comment = f'-{run}'\n",
    "        \n",
    "        for epoch in range(end_epoch):\n",
    "            \n",
    "            train_data.reset() # shuffle\n",
    "            \n",
    "            epoch_acc = 0.0\n",
    "            \n",
    "            for batch_idx,(image,(gt_label,gt_bbox,gt_landmark))in enumerate(train_data):\n",
    "                \n",
    "                im_tensor = [ image_tools.convert_image_to_tensor(image[i,:,:,:]) for i in range(image.shape[0]) ]\n",
    "                \n",
    "                im_tensor = torch.stack(im_tensor)\n",
    "\n",
    "                im_tensor = Variable(im_tensor)\n",
    "                \n",
    "                gt_label = Variable(torch.from_numpy(gt_label).float())\n",
    "\n",
    "                gt_bbox = Variable(torch.from_numpy(gt_bbox).float())\n",
    "                \n",
    "                gt_landmark = Variable(torch.from_numpy(gt_landmark).float())\n",
    "                \n",
    "                cls_pred, box_offset_pred,landmark_offset_pred = network(im_tensor)\n",
    "                \n",
    "                cls_loss = lossfn.cls_loss(gt_label,cls_pred)\n",
    "                \n",
    "                box_offset_loss = lossfn.box_loss(gt_label,gt_bbox,box_offset_pred)\n",
    "                \n",
    "                landmark_loss = lossfn.landmark_loss(gt_label,gt_landmark,landmark_offset_pred)\n",
    "                \n",
    "                all_loss  = cls_loss*1.0+box_offset_loss*0.5\n",
    "                \n",
    "                cls_pred, box_offset_pred = network(im_tensor)\n",
    "                \n",
    "                if batch_idx%frequent==0:\n",
    "                    accuracy=compute_accuracy(cls_pred,gt_label)\n",
    "                    accuracy=compute_accuracy(cls_pred,gt_label)\n",
    "                    show1 = accuracy.data.cpu().numpy()\n",
    "                    show2 = cls_loss.data.cpu().numpy()\n",
    "                    show3 = box_offset_loss.data.cpu().numpy()\n",
    "                    show4 = landmark_loss.data.cpu().numpy()\n",
    "                    show5 = all_loss.data.cpu().numpy()\n",
    "                    print(\"%s : Epoch: %d, Step: %d, accuracy: %s, det loss: %s, bbox loss: %s, landmark_loss: %s all_loss: %s, lr:%s \"%\n",
    "                            (datetime.datetime.now(),epoch,batch_idx, show1,show2,show3,show4,show5,run.lr))\n",
    "                    epoch_acc = show1\n",
    "                #计算偏差矩阵\n",
    "                optimizer.zero_grad()\n",
    "                all_loss.backward()\n",
    "                optimizer.step()\n",
    "                pass\n",
    "            \n",
    "            pass\n",
    "            print('save modle acc:', epoch_acc)\n",
    "            torch.save(network.state_dict(), os.path.join(model_store_path,\"onet_epoch_%d.pt\" % epoch))\n",
    "            torch.save(network, os.path.join(model_store_path,\"onet_epoch_model_%d.pkl\" % epoch))\n",
    "            pass\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    pass              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('train Onet Process:...')\n",
    "    #加载图片文件\n",
    "    #imagedb = ImageDB(annotation_file,'./image/train')\n",
    "    #gt_imdb = imagedb.load_imdb()\n",
    "    #gt_imdb = imagedb.append_flipped_images(gt_imdb)\n",
    "    train_net()\n",
    "    print('finish....')\n",
    "    #print(gt_imdb[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

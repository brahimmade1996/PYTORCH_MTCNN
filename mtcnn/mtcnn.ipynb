{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch package\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# add other package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tool.plotcm import plot_confusion_matrix\n",
    "import tool.image_tools\n",
    "\n",
    "import pdb\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "#torch.set_printoptions(linewidth=120)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义神经网络\n",
    "\n",
    "1. 定义模型属性\n",
    "2. 定义forward函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义PNet\n",
    "\n",
    "1. 输入图片 12*12*3\n",
    "2. 三个输出代表：人脸分类、人脸框的回归和人脸关键点定位\n",
    "3. bound的4个坐标信息和score 4*1*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3111, -0.0241,  1.7085, -0.3845])\n",
      "torch.Size([4, 3, 12, 12])\n",
      "b tensor([0.5025, 0.4923, 0.5576, 0.4825], grad_fn=<SqueezeBackward0>)\n",
      "a: tensor([True, True, True, True])\n",
      "c tensor([0.5025, 0.4923, 0.5576, 0.4825], grad_fn=<MaskedSelectBackward>)\n",
      "c tensor([True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#input 12*12*3\n",
    "class PNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10,out_channels=16,kernel_size=3)\n",
    "        self.out = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3)\n",
    "        \n",
    "        self.det = nn.Conv2d(in_channels=32,out_channels=1,kernel_size=1)\n",
    "        self.bound = nn.Conv2d(in_channels=32,out_channels=4,kernel_size=1)\n",
    "        self.landmark = nn.Conv2d(in_channels=32,out_channels=10,kernel_size=1)\n",
    "        self.apply(weights_init)\n",
    "        pass\n",
    "    \n",
    "    def forward(self,tensor):\n",
    "        #layer input\n",
    "        input=tensor\n",
    "        #layer 1\n",
    "        t=self.conv1(input)\n",
    "        t = F.relu(t)\n",
    "        #print('pnet conv1 shape:',t.shape)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        #print('pnet mp1 shape:',t.shape)\n",
    "        #layer 2\n",
    "        t=self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        #print('pnet conv2 shape:',t.shape)\n",
    "        #layer 3\n",
    "        t = self.out(t)\n",
    "        #print('pnet out shape:',t.shape)\n",
    "        # t = F.relu(t)\n",
    "        #out label face 1*1*2\n",
    "        det = self.det(t)\n",
    "        label = F.sigmoid(det)\n",
    "        #out bounding box (1*1*4)\n",
    "        bound = self.bound(t)\n",
    "        offset = F.relu(bound)\n",
    "        #landmark = self.landmark(t)\n",
    "        return label,offset\n",
    "    pass\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "t = torch.rand([4,3,12,12])\n",
    "\n",
    "\n",
    "label = torch.randn([4])\n",
    "\n",
    "print(label)\n",
    "\n",
    "print(t.shape)\n",
    "\n",
    "pnet =PNet()\n",
    "\n",
    "plabel,offset = pnet(t)\n",
    "\n",
    "plabel = plabel.squeeze()\n",
    "\n",
    "mask = torch.ge(plabel,0)\n",
    "\n",
    "valid_gt_cls = torch.masked_select(plabel,mask)\n",
    "\n",
    "\n",
    "prob_ones = torch.ge(valid_gt_cls,0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('b',plabel)\n",
    "\n",
    "print('a:',mask)\n",
    "\n",
    "print('c',valid_gt_cls)\n",
    "\n",
    "print('c',prob_ones)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义RNet\n",
    "\n",
    "1. R-Net主要用来去除大量的非人脸框\n",
    "\n",
    "2. 输入是PNet的bound矩阵 24*24*3大小 可以resize Pnet 的offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnet out label shape: torch.Size([4, 2])\n",
      "Rnet out offset shape: torch.Size([4, 4])\n",
      "a torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "#input 24*24*3\n",
    "class RNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=28,kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=28,out_channels=48,kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=48,out_channels=64,kernel_size=2)\n",
    "        self.out = nn.Linear(in_features=3*3*64,out_features=128)\n",
    "        \n",
    "        self.det = nn.Linear(in_features=128,out_features=2)\n",
    "        self.bound = nn.Linear(in_features=128,out_features=4)\n",
    "        self.landmark = nn.Linear(in_features=128,out_features=10)\n",
    "        pass\n",
    "    \n",
    "    def forward(self,tensor):\n",
    "        #layer input\n",
    "        input = tensor\n",
    "        #layer 1\n",
    "        t=self.conv1(input)\n",
    "        t=F.relu(t)\n",
    "        #print('RNet conv1 shape:',t.shape)\n",
    "        t=F.max_pool2d(t,kernel_size=3,stride=2)\n",
    "        #print('RNet MP1 3*3 shape:',t.shape)\n",
    "        #layer 2\n",
    "        t=self.conv2(t)\n",
    "        t=F.relu(t)\n",
    "        #print('RNet conv2 shape: ',t.shape)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        #print('RNet MP2 3*3 shape: ',t.shape)\n",
    "        #layer3\n",
    "        t=self.conv3(t)\n",
    "        t=F.relu(t)\n",
    "        #print('RNet conv3 shape: ',t.shape)\n",
    "        #layer out\n",
    "        t = t.reshape(-1, 3*3*64)\n",
    "        #print('RNet out reshape: ',t.shape)\n",
    "        t=self.out(t)\n",
    "        #print('RNet out shape: ',t.shape)\n",
    "        \n",
    "        #out label face B*2\n",
    "        det = self.det(t)\n",
    "        label = F.relu(det)\n",
    "        print('Rnet out label shape:',label.shape)\n",
    "        #out bounding box (B*4)\n",
    "        bound = self.bound(t)\n",
    "        offset = F.relu(bound)\n",
    "        print('Rnet out offset shape:',offset.shape)\n",
    "        #out landmark \n",
    "        #landmark = self.landmark(t)\n",
    "        #landmark = F.relu(landmark)\n",
    "        #print('Rnet out offset shape:',landmark.shape)\n",
    "        return label,offset\n",
    "    pass\n",
    "\n",
    "t=torch.randn([4,3,24,24])\n",
    "\n",
    "\n",
    "\n",
    "label=torch.randn([4])\n",
    "\n",
    "rnet=RNet()\n",
    "\n",
    "rlabel,roffset = rnet(t)\n",
    "\n",
    "\n",
    "#cm = confusion_matrix(label, rlabel.argmax(dim=1),labels=[1])\n",
    "\n",
    "\n",
    "print('a',rlabel.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义ONet\n",
    "\n",
    "1. ONet和RNet有些像，只不过这一步还增加了landmark位置的回归\n",
    "\n",
    "2. 输入大小调整为48*48 ,RNet输出的Bound即offset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 48, 48])\n",
      "Rnet out label shape: torch.Size([4, 2])\n",
      "Rnet out offset shape: torch.Size([4, 4])\n",
      "Rnet out offset shape: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "#input 48*48*3\n",
    "class ONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=2)\n",
    "        self.out = nn.Linear(in_features=3*3*128,out_features=256)\n",
    "        \n",
    "        self.det = nn.Linear(in_features=256,out_features=2)\n",
    "        self.bound = nn.Linear(in_features=256,out_features=4)\n",
    "        self.landmark = nn.Linear(in_features=256,out_features=10)\n",
    "        pass\n",
    "    def forward(self,tensor):\n",
    "        #layer input\n",
    "        input = tensor\n",
    "        #layer 1\n",
    "        t=self.conv1(input)\n",
    "        t=F.relu(t)\n",
    "        #print('ONet conv1 shape:',t.shape)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        #print('ONet MP1:3*3 shape:',t.shape)\n",
    "        #layer 2\n",
    "        t=self.conv2(t)\n",
    "        t=F.relu(t)\n",
    "        #print('ONet conv2 shape:',t.shape)\n",
    "        t=F.max_pool2d(t,kernel_size=3,stride=2)\n",
    "        #print('ONet MP2:3*3 shape:',t.shape)\n",
    "        #layer3\n",
    "        t=self.conv3(t)\n",
    "        t=F.relu(t)\n",
    "        #print('ONet conv3 shape:',t.shape)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        #print('ONet MP2:2*2 shape:',t.shape)\n",
    "        #layer 4\n",
    "        t=self.conv4(t)\n",
    "        t=F.relu(t)\n",
    "        #print('ONet conv4 shape:',t.shape)\n",
    "        t=t.reshape(-1,128*3*3)\n",
    "        #layer out\n",
    "        t=self.out(t)\n",
    "        #print('ONet out shape:',t.shape)\n",
    "        \n",
    "        #out label face B*2\n",
    "        det = self.det(t)\n",
    "        label = F.relu(det)\n",
    "        print('Rnet out label shape:',label.shape)\n",
    "        #out bounding box (B*4)\n",
    "        bound = self.bound(t)\n",
    "        offset = F.relu(bound)\n",
    "        print('Rnet out offset shape:',offset.shape)\n",
    "        #landmark = self.landmark(t)\n",
    "        landmark = self.landmark(t)\n",
    "        landmark = F.relu(landmark)\n",
    "        print('Rnet out offset shape:',landmark.shape)\n",
    "        return label,offset,landmark\n",
    "    pass\n",
    "\n",
    "t=torch.randn([4,3,48,48])\n",
    "\n",
    "print(t.shape)\n",
    "\n",
    "onet=ONet()\n",
    "\n",
    "label,offset,landmark = onet(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型 建立标准函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ger_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def ger_all_preds(model,train_data):\n",
    "    all_preds=torch.tensor([])\n",
    "    for batch in train_data:\n",
    "        images,labels = batch\n",
    "        preds=model(images)\n",
    "        torch.cat((all_preds,preds),dim=0)\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  0.01 1000 True\n",
      "Title:  0.01 1000 False\n",
      "Title:  0.01 10000 True\n",
      "Title:  0.01 10000 False\n",
      "Title:  0.001 1000 True\n",
      "Title:  0.001 1000 False\n",
      "Title:  0.001 10000 True\n",
      "Title:  0.001 10000 False\n"
     ]
    }
   ],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epoch():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.loss = 0\n",
    "        self.num_correct = 0\n",
    "        self.start_time = None\n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        pass\n",
    "\n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self.get_num_correct(preds, labels)\n",
    "        \n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFn:\n",
    "    def __init__(self, cls_factor=1, box_factor=1, landmark_factor=1):\n",
    "        # loss function\n",
    "        self.cls_factor = cls_factor\n",
    "        self.box_factor = box_factor\n",
    "        self.land_factor = landmark_factor\n",
    "        self.loss_cls = nn.BCELoss() \n",
    "        # binary cross entropy\n",
    "        self.loss_box = nn.MSELoss() \n",
    "        # mean square error\n",
    "        self.loss_landmark = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def cls_loss(self,gt_label,pred_label):\n",
    "        pred_label = torch.squeeze(pred_label)\n",
    "        gt_label = torch.squeeze(gt_label)\n",
    "        # get the mask element which >= 0, only 0 and 1 can effect the detection loss\n",
    "        mask = torch.ge(gt_label,0)\n",
    "        valid_gt_label = torch.masked_select(gt_label,mask)\n",
    "        valid_pred_label = torch.masked_select(pred_label,mask)\n",
    "        return self.loss_cls(valid_pred_label,valid_gt_label)*self.cls_factor\n",
    "\n",
    "\n",
    "    def box_loss(self,gt_label,gt_offset,pred_offset):\n",
    "        pred_offset = torch.squeeze(pred_offset)\n",
    "        gt_offset = torch.squeeze(gt_offset)\n",
    "        gt_label = torch.squeeze(gt_label)\n",
    "\n",
    "        #get the mask element which != 0\n",
    "        unmask = torch.eq(gt_label,0)\n",
    "        mask = torch.eq(unmask,0)\n",
    "        #convert mask to dim index\n",
    "        chose_index = torch.nonzero(mask.data)\n",
    "        chose_index = torch.squeeze(chose_index)\n",
    "        #only valid element can effect the loss\n",
    "        valid_gt_offset = gt_offset[chose_index,:]\n",
    "        valid_pred_offset = pred_offset[chose_index,:]\n",
    "        return self.loss_box(valid_pred_offset,valid_gt_offset)*self.box_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "\n",
    "def assemble_data(output_file, anno_file_list=[]):\n",
    "\n",
    "    #assemble the pos, neg, part annotations to one file\n",
    "    size = 12\n",
    "\n",
    "    if len(anno_file_list)==0:\n",
    "        return 0\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    for anno_file in anno_file_list:\n",
    "        with open(anno_file, 'r') as f:\n",
    "            print(anno_file)\n",
    "            anno_lines = f.readlines()\n",
    "\n",
    "        base_num = 250000\n",
    "\n",
    "        if len(anno_lines) > base_num * 3:\n",
    "            idx_keep = npr.choice(len(anno_lines), size=base_num * 3, replace=True)\n",
    "        elif len(anno_lines) > 100000:\n",
    "            idx_keep = npr.choice(len(anno_lines), size=len(anno_lines), replace=True)\n",
    "        else:\n",
    "            idx_keep = np.arange(len(anno_lines))\n",
    "            np.random.shuffle(idx_keep)\n",
    "        chose_count = 0\n",
    "        with open(output_file, 'a+') as f:\n",
    "            for idx in idx_keep:\n",
    "                # write lables of pos, neg, part images\n",
    "                f.write(anno_lines[idx])\n",
    "                chose_count+=1\n",
    "\n",
    "    return chose_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
